###################### Automated Depth Profiling Technique #####################

# The method created by Wang et al. (2025) to quantitatively segment depth profiling age plateaus.

################# STEP 1: INSTALL REQUIRED PACKAGES IF NECESSARY ###############
# Check and Install Missing Packages
pack1 <- suppressWarnings(require(stats))
if(pack1 == FALSE) {install.packages("stats"); library(stats)}
pack2 <- suppressWarnings(require(MASS))
if(pack2 == FALSE) {install.packages("MASS"); library(MASS)}
pack3 <- suppressWarnings(require(ggplot2))
if(pack3 == FALSE) {install.packages("ggplot2"); library(ggplot2)}
pack4 <- suppressWarnings(require(zoo))
if(pack4 == FALSE) {install.packages("zoo"); library(zoo)}
pack5 <- suppressWarnings(require(changepoint))
if(pack5 == FALSE) {install.packages("changepoint"); library(changepoint)}
pack6 <- suppressWarnings(require(readxl))
if(pack6 == FALSE) {install.packages("readxl"); library(readxl)}
pack7 <- suppressWarnings(require(nlme))
if(pack7 == FALSE) {install.packages("nlme"); library(nlme)}
pack8 <- suppressWarnings(require(tidyverse))
if(pack8 == FALSE) {install.packages("tidyverse"); library(tidyverse)}
pack9 <- suppressWarnings(require(mlbench))
if(pack9 == FALSE) {install.packages("mlbench"); library(mlbench)}
pack10 <- suppressWarnings(require(Matrix))
if(pack10 == FALSE) {install.packages("Matrix"); library(Matrix)}
pack11 <- suppressWarnings(require(dplyr))
if(pack11 == FALSE) {install.packages("dplyr"); library(dplyr)}
pack12 <- suppressWarnings(require(forecast))
if(pack12 == FALSE) {install.packages("forecast"); library(forecast)}
pack13 <- suppressWarnings(require(openxlsx))
if(pack13 == FALSE) {install.packages("openxlsx"); library(openxlsx)}
pack14 <- suppressWarnings(require(gridExtra))
if(pack14 == FALSE) {install.packages("gridExtra"); library(gridExtra)}
pack15 <- suppressWarnings(require(png))
if(pack15 == FALSE) {install.packages("png"); library(png)}
pack16 <- suppressWarnings(require(mcp))
if(pack16 == FALSE) {install.packages("mcp"); library(mcp)}
pack17 <- suppressWarnings(require(writexl))
if(pack17 == FALSE) {install.packages("writexl"); library(writexl)}
pack18 <- suppressWarnings(require(IsoplotR))
if(pack18 == FALSE) {install.packages("IsoplotR"); library(IsoplotR)}

# Clear Temporary Variables
rm(pack1, pack2, pack3, pack4, pack5, pack6, pack7, pack8, pack9, pack10, pack11, pack12, pack13, pack14, pack15, pack16, pack17, pack18)

# Clean Up the Working Environment
rm(list = ls())

################ STEP 2 Set the Working Directory and Parameters ###############

setwd("E:/2025 Wang et al/Automated Depth Profiling Technique") #Set the working directory
file_path <- "E:/2025 Wang et al/Automated Depth Profiling Technique/Input.xlsx"  # Please replace with your file path

# Set Parameters
chunk_size <- 411
Lower_limit_of_ablation_time <- 29
Upper_limit_of_ablation_time <- 58
Maximum_age_limit <- 4540 
Minimum_age_limit <- 0 
Minimum_age_plateau_resolution <- NA
Fluctuating_age_variance_threshold <- 0.1192

################################################################################

# Create an empty ggplot list
plots <- list()
# Get all sheet names from the Excel file
sheet_names <- readxl::excel_sheets(file_path)
# Create an empty list to store data from each sheet
data_list <- list()
# Loop through and read data from each sheet
for (i in seq_along(sheet_names)) {
  data_list[[sheet_names[i]]] <- openxlsx::read.xlsx(file_path, sheet = sheet_names[i])
}

####################### Read data to create a data frame #######################

# Create a data frame
output <- data.frame(Analysis = factor(),Group = numeric(), Points = numeric(),
                     Start = numeric(),End = numeric(),
                     Time_step = numeric(),Max_step = numeric(),Min_step = numeric(),
                     standardized_Mean = numeric(),Segment_Mean =  numeric(),
                     Variance = numeric(),
                     Calibration_uncertainty =  numeric(), Plateau_uncertainty =  numeric(), Total_uncertainty =  numeric(),
                     Filter_1 = numeric(),Filter_2 = numeric(),
                     Filter_3 = numeric(),Filter_4 = numeric(),
                     Plateau_Numbers = numeric(),Mean_numbers = numeric(), 
                     Final_step_Numbers = numeric(), Final_Serial_Number = numeric(),
                     Final_Age = numeric(), Final_total_uncertainty = numeric()
)

# Retrieve data from the current sheet
for (sheet_name in sheet_names) {
  segment.data.raw <- data_list[[sheet_name]] 
  n_groups <- ceiling(nrow(segment.data.raw) / chunk_size)
  group_counter <- 1
  
  for (i in 1:n_groups) {
    start_row <- (i - 1) * chunk_size + 1
    end_row <- min(i * chunk_size, nrow(segment.data.raw))
    colnames(segment.data.raw) <- gsub(" |/", "_", colnames(segment.data.raw))
    
    # Requires age data, elemental data, or isotope data
    if("Age68" %in% colnames(segment.data.raw) && 
       !all(is.na(segment.data.raw$Age68[start_row:end_row]))){
      segment.data <- data.frame(
        Analysis = segment.data.raw$Analysis[start_row:end_row],
        Time = segment.data.raw$Time[start_row:end_row],
        Age68= segment.data.raw$Age68[start_row:end_row],
        Age75= segment.data.raw$Age75[start_row:end_row],
        Age76= segment.data.raw$Age76[start_row:end_row]
      )
      segment.data[,2:5] <- lapply(segment.data[, 2:5], as.numeric)
    }else if("Pb206" %in% colnames(segment.data.raw) && 
             !all(is.na(segment.data.raw$Pb206[start_row:end_row]))){
      
      segment.data <- data.frame(
        Analysis = segment.data.raw$Analysis[start_row:end_row],
        Time = segment.data.raw$Time[start_row:end_row],
        Pb206 = segment.data.raw$Pb206[start_row:end_row],
        Pb207 = segment.data.raw$Pb207[start_row:end_row],
        U238 = segment.data.raw$U238[start_row:end_row]
      )
      segment.data[,2:5] <- lapply(segment.data[, 2:5], as.numeric)
      segment.data$U235 = segment.data$U238/137.88
      segment.data$Pb206U238 <- segment.data$Pb206 / segment.data$U238
      segment.data$Pb207U235 <- segment.data$Pb207 / segment.data$U235
      segment.data$Pb207Pb206 <- segment.data$Pb207 / segment.data$Pb206
      # Define a function to calculate age (assuming error is 0)
      calculate_age <- function(ratio, method) {
        if (is.finite(ratio) && ratio > 0) {
          # Input is a two-element vector: c(ratio, 0)
          input <- c(ratio, 0)
          # Call the age() function and specify the method
          result <- age(input, method = method, exterr = FALSE)
          return(result[1])  # Return the age value
        } else {
          return(NA)
        }
      }
      
      # Calculate the ages for Pb206_U238, Pb207_U235, and Pb207_Pb206
      segment.data$Age68 <- sapply(segment.data$Pb206U238, calculate_age, method = 'U238-Pb206')
      segment.data$Age75 <- sapply(segment.data$Pb207U235, calculate_age, method = 'U235-Pb207')
      segment.data$Age76 <- sapply(segment.data$Pb207Pb206, calculate_age, method = 'Pb207-Pb206')
      
    }else if("Pb206_U238" %in% colnames(segment.data.raw) && 
             !all(is.na(segment.data.raw$Pb206_U238[start_row:end_row]))){
      segment.data <- data.frame(
        Analysis = segment.data.raw$Analysis[start_row:end_row],
        Time = segment.data.raw$Time[start_row:end_row],
        Pb206U238 = segment.data.raw$Pb206_U238[start_row:end_row],
        Pb207U235 = segment.data.raw$Pb207_U235[start_row:end_row],
        Pb207Pb206 = segment.data.raw$Pb207_Pb206[start_row:end_row]
      )
      segment.data[, 2:5] <- lapply(segment.data[, 2:5], as.numeric)
      
      # Define a function to calculate age (assuming error is 0)
      calculate_age <- function(ratio, method) {
        if (is.finite(ratio) && ratio > 0) {
          # Input is a two-element vector: c(ratio, 0)
          input <- c(ratio, 0)
          # Call the age() function and specify the method
          result <- age(input, method = method, exterr = FALSE)
          return(result[1]) 
        } else {
          return(NA)
        }
      }
      
      # Calculate the ages for Pb206_U238, Pb207_U235, and Pb207_Pb206
      segment.data$Age68 <- sapply(segment.data$Pb206U238, calculate_age, method = 'U238-Pb206')
      segment.data$Age75 <- sapply(segment.data$Pb207U235, calculate_age, method = 'U235-Pb207')
      segment.data$Age76 <- sapply(segment.data$Pb207Pb206, calculate_age, method = 'Pb207-Pb206')
    }
    
    # Determine if Age68, Age75, and Age76 have too many missing ages.
    if (all(is.na(segment.data$Age68)) || all(is.na(segment.data$Age75)) || all(is.na(segment.data$Age76))) {
      output <- rbind(output, c(segment.data[1,1],group_counter, nrow(subset_data),
                                NA,NA,NA,
                                NA,NA,
                                NA,NA,
                                0,NA,NA,
                                NA,NA,NA,
                                NA,NA,NA,
                                NA,NA
      ))
      print(paste("Group", i, segment.data[1,1],"MISSING  (Age68, Age75, Age76)"))
      group_counter <- group_counter + 1
      next
    }
    
    # Set the effective ablation time
    segment.data[, c(2:ncol(segment.data))] <- sapply(segment.data[, c(2:ncol(segment.data))], as.numeric)
    segment.data <- na.omit(segment.data)
    subset_data <- subset(segment.data, Time >= Lower_limit_of_ablation_time & Time <= Upper_limit_of_ablation_time )
    subset_data$Raw_Age <- ifelse(subset_data$Age68 < 1000, subset_data$Age68,  ifelse(subset_data$Age76 > 1000, subset_data$Age76, NA))
    
    # Determine if Age68, Age75, and Age76 have too many missing ages.
    if (all(is.na(subset_data$Age68)) || all(is.na(subset_data$Age75)) || all(is.na(subset_data$Age76))) {
      output <- rbind(output, c(segment.data[1,1],group_counter, nrow(subset_data),
                                NA,NA,NA,
                                NA,NA,
                                NA,NA,
                                0,NA,NA,
                                NA,NA,NA,
                                NA,NA,NA,
                                NA,NA
      ))
      print(paste("Group", i, segment.data[1,1],"MISSING  (Age68, Age75, Age76)"))
      group_counter <- group_counter + 1
      next
    }
    
###################### ARIMA Model for Identifying Outliers ####################
    
    detect_outliers_arima <- function(series) {
      arima_model <- auto.arima(series)
      residuals <- residuals(arima_model)
      outlier_indices <- which(abs(residuals) > 2 * sd(residuals))
      series[outlier_indices] <- NA
      return(series)
    }
    subset_data$Age68 <- detect_outliers_arima(subset_data$Age68)
    subset_data$Age75 <- detect_outliers_arima(subset_data$Age75)
    subset_data$Age76 <- detect_outliers_arima(subset_data$Age76)
    
########################### Exclude discordant ages ############################
    
    subset_data$Age <- ifelse(subset_data$Age68 < 1000, subset_data$Age68,  ifelse(subset_data$Age76 > 1000, subset_data$Age76, NA))
    subset_data$subset_Age68 <- ifelse(abs(subset_data$Age68 - subset_data$Age75) / subset_data$Age75 <= 0.1, subset_data$Age68, NA)
    #subset_data$subset_Age76 <- ifelse(abs(subset_data$Age76 - subset_data$Age75) / subset_data$Age75 <= 0.1, subset_data$Age76, NA)
    subset_data$subset_Age76 <- subset_data$Age76
    
#################### Apply mean filtering to handle outliers ###################
    
    calculate_mean <- function(series, index, window_size = 5) {
      start_index <- max(1, index - window_size)
      end_index <- min(length(series), index + window_size)
      return(mean(series[start_index:end_index], na.rm = TRUE))
    }
    fill_na_with_mean <- function(na_series, original_series) {
      na_indices <- which(is.na(na_series))
      for (index in na_indices) {
        na_series[index] <- calculate_mean(original_series, index)
      }
      return(na_series)
    }
    
    subset_data$subset_Age68 <- fill_na_with_mean(subset_data$subset_Age68, subset_data$Age68)
    subset_data$subset_Age76 <- fill_na_with_mean(subset_data$subset_Age76, subset_data$Age76)
    subset_data$subset_Age <- ifelse(subset_data$subset_Age68 < 1000, subset_data$subset_Age68, ifelse(subset_data$subset_Age76 > 1000, subset_data$subset_Age76, NA))
    
################## Determine if Age have too many missing ages #################
    
    if ( nrow(subset_data[which(!is.na(subset_data$subset_Age)),]) < 10) {
      output <- rbind(output, c(segment.data[1,1],group_counter, nrow(subset_data),
                                NA,NA,NA,
                                NA,NA,
                                NA,NA,
                                0,NA,NA,
                                NA,NA,NA,
                                NA,NA,NA,
                                NA,NA
      ))
      print(paste("Group", group_counter,subset_data[1,1], "After 10% Empty "))
      group_counter <- group_counter + 1
      next
    }
    subset_data <- subset_data[complete.cases(subset_data$subset_Age), ]
    subset_data$Row_Number <- 1:nrow(subset_data)
    
############################# LOESS Smoothing of Data ########################## 
    
    # Perform loess fitting using span = 0.15
    loess_model <- loess(subset_Age ~ Time, data = subset_data, span = 0.15)
    subset_data$loess_Age <- predict(loess_model)
    
    # Remove missing values
    subset_data <- subset_data[complete.cases(subset_data$loess_Age), ]
    
    # Optionally, take the logarithm by adding a log function (not added here for now)
    subset_data$log_loess <- subset_data$loess_Age
    subset_data$log_Age <- subset_data$Age
    
    #标准化处理数据
    minage <- min(subset_data$log_Age)
    maxage <- max(subset_data$log_Age)
    
    minloess <- min(subset_data$log_loess)
    maxloess <- max(subset_data$log_loess)
    
    subset_data$standardized_loess  <- (subset_data$log_loess - minloess)/(maxloess - minloess)
    subset_data$standardized_Age  <- (subset_data$log_Age - minloess)/(maxloess - minloess)
    subset_data <- subset_data[complete.cases(subset_data$standardized_loess), ]
    
    if ( nrow(subset_data[which(!is.na(subset_data$standardized_loess)),]) < 10) {
      output <- rbind(output, c(segment.data[1,1],group_counter, nrow(subset_data),
                                NA,NA,NA,
                                NA,NA,
                                NA,NA,
                                0,NA,NA,
                                NA,NA,NA,
                                NA,NA,NA,
                                NA,NA
      ))
      print(paste("Group", group_counter,subset_data[1,1], "After 10% Empty "))
      group_counter <- group_counter + 1
      next
    }
    
####################### PELT Segmentation of Age Plateaus ######################
    
    # Calculate the penalty value SAIC = (AIC/100) * ln(n)
    AIC_result <- cpt.mean(subset_data$standardized_loess, method = "PELT", penalty = "AIC", minseglen = 1)
    aic_pen_value <- attr(AIC_result, "pen.value")
    SAIC <- (aic_pen_value/100)*log(nrow(subset_data))
    
    # Calculate the initial age plateau
    cpt_result.loess <- cpt.mean(subset_data$standardized_loess, method = "PELT",penalty =  "Manual" , pen.value = SAIC, minseglen = 1)
    changepoint <- cpt_result.loess@cpts
    subset_data$Change_loess <- ifelse( subset_data$Row_Number %in% changepoint, "YES", "NO")
    
    segments_data <- data.frame(
      Start = subset_data$Time[c(1, head(changepoint, -1) + 1)],
      End = subset_data$Time[changepoint],
      standardized_loess = subset_data$standardized_loess[changepoint]
    )
    
    # Calculate the plateau values (this step represents the plateau values under standardized conditions)
    segments_data$standardized_Mean <- sapply(1:nrow(segments_data), function(i) {
      mean(subset_data$standardized_loess[segments_data$Start[i] <= subset_data$Time & subset_data$Time <= segments_data$End[i]])
    })
    
########### Standardize each data segment and calculate the variance ###########
    
    normalize_segment <- function(series, start, end) {
      segment <- series[start:end]
      normalized_segment <- (segment - min(segment)) / (max(segment) - min(segment))
      return(normalized_segment)
    }
    
    # Retrieve the start and end points of each data segment
    segment_starts <- c(1, head(changepoint, -1) + 1)
    segment_ends <- changepoint
    
    # Standardize each data segment
    normalized_segments <- lapply(1:length(segment_starts), function(i) {
      normalize_segment(subset_data$loess_Age, segment_starts[i], segment_ends[i])
    })
    
    # Add the standardized data segments to the subset_data dataframe
    subset_data$IS_loess <- unlist(normalized_segments)
    
######## Calculate the plateau values and variance of the original data ########
    
    subset_data$Restored_loess <- (as.numeric(subset_data$standardized_loess))*(maxloess-minloess)+minloess
    subset_data$Restored_age <- (as.numeric(subset_data$standardized_Age))*(maxloess-minloess)+minloess
    
    segments_data$Restored_loess <- subset_data$Restored_loess[changepoint]
    
    # Calculate the age plateau
    segments_data$Segment_Mean <- sapply(1:nrow(segments_data), function(i) {
      mean(subset_data$Restored_loess[segments_data$Start[i] <= subset_data$Time & subset_data$Time <= segments_data$End[i]])
    })
    

    segments_data$Number <- 1:nrow(segments_data)
    
    # Calculate the time interval
    segments_data$Time_step <- sapply(1:nrow(segments_data), function(i) {
      subset_data$Time_step[segments_data$Start[i] <= subset_data$Time & subset_data$Time <= segments_data$End[i]]
    })
    
    # Calculate the length of the plateau (time) in seconds
    segments_data$Time_step <- segments_data$End - segments_data$Start
    segments_data$Max_step <- max(segments_data$Time_step)
    segments_data$Min_step <- min(segments_data$Time_step)
    
################## Calculate the variance of the age plateau ###################
    
    calculate_variance <- function(series, start, end) {
      variance <- var(series[start:end], na.rm = TRUE)
      return(variance)
    }
    
    segment_starts <- c(1, head(changepoint, -1) + 1)
    segment_ends <- changepoint
    
    segments_data$Variance <- sapply(1:length(segment_starts), function(i) {
      calculate_variance(subset_data$IS_loess, segment_starts[i], segment_ends[i])
    })

##################### Calculate the uncertainty of the age plateau ###################
    
    # 1 Calculate the calibration uncertainty
    segments_data$Calibration_uncertainty <- segments_data$Segment_Mean*0.03
    
    # 2 Calculate the Plateau uncertainty
    segments_data$Plateau_uncertainty <- sapply(1:length(segment_starts), function(i) {
      segment <- subset_data$Raw_Age[segment_starts[i]:segment_ends[i]]
      segment_no_na <- segment[!is.na(segment)]
      n_points <- length(segment_no_na)
      if (n_points < 2) return(NA)  # sd requires at least 2 points
      sd_val <- sd(segment_no_na)
      return(sd_val / sqrt(n_points))
    })
    
    # 3 Total uncertainty = √(calibration uncertainty² + plateau uncertainty²)
    segments_data$Total_uncertainty <- sqrt(
      segments_data$Calibration_uncertainty^2 + 
        segments_data$Plateau_uncertainty^2
    )
    
############################ Filter the age plateau ############################
    
    # 1 First filtering: Age range 
    #(default zircon age is less than Earth's age 4540 Ma and greater than 0 Ma)
    segments_data$Filter_1 <- ifelse(as.numeric(segments_data$Segment_Mean) <= Maximum_age_limit & 
                                       as.numeric(segments_data$Segment_Mean) >= Minimum_age_limit, 
                                     segments_data$Segment_Mean, NA)
    
    # 2 Second filtering: Variation
    segments_data$Filter_2 <- ifelse( as.numeric(segments_data$Variance) <= Fluctuating_age_variance_threshold , segments_data$Filter_1 , NA )
    
    # 3 Third filtering: Minimum age plateau resolution
    Identification_resolution <- ifelse(is.na(Minimum_age_plateau_resolution) | Minimum_age_plateau_resolution > 5, 5, Minimum_age_plateau_resolution)
    segments_data$Filter_3 <- c(segments_data$Filter_2[1], ifelse(as.numeric(segments_data$Time_step[-1]) >= Identification_resolution, segments_data$Filter_2[-1], NA))
    
    # 4 Fourth filtering: Metamorphic zircon
    NO_NULL_Age <- segments_data$Filter_3[!is.na(segments_data$Filter_3)]
    is_sorted <- all(diff(NO_NULL_Age, na.rm = TRUE) >= 0)
    is_no_sorted <- all(diff(NO_NULL_Age, na.rm = TRUE) < 0)
    
    # 4.1 Determine if the age plateau sequence is ascending
    if (is_sorted) {
      segments_data$Filter_4 <- segments_data$Filter_3
    } else if (is_no_sorted) {
    # 4.2 Determine if the age plateau sequence is descending
      segments_data$Filter_4[segments_data$Filter_3 %in% NO_NULL_Age[1]] <- NO_NULL_Age[1]
    } else {  segments_data$Filter_4 <- NA
    # 4.3 If the age arrangement is volatile, retain the first plateau and the most stable plateau
    segments_data$Filter_4[segments_data$Filter_3 %in% NO_NULL_Age[1]] <- NO_NULL_Age[1]
    segments_data$Filter_4[ segments_data$Variance %in% min(segments_data$Variance[ !is.na(segments_data$Filter_3) & is.na(segments_data$Filter_4) ])] <- 
      segments_data$Filter_3[ segments_data$Variance %in% min(segments_data$Variance[ !is.na(segments_data$Filter_3) & is.na(segments_data$Filter_4) ])]
    }
    segments_data$Final_total_uncertainty <- ifelse(!is.na(segments_data$Filter_4),segments_data$Total_uncertainty,NA)
    
    # Final number of age plateaus per sample
    segments_data$Plateau_Numbers <- length(segments_data$Filter_4)
    # Final sequence numbers of the age plateaus
    segments_data$Final_Serial_Number <- NA
    non_na_indices <- which(!is.na(segments_data$Filter_4))
    segments_data$Final_Serial_Number[non_na_indices] <- seq_along(non_na_indices)
    
    # Mark the final age plateaus in red
    Final_color <-  ifelse(!is.na(segments_data$Filter_4), "red" ,NA)
    
    d <- ggplot() +
      geom_point(data = subset_data, aes(x = Time, y = Raw_Age), color = "#f46f20", shape = 16, size = 1.1, alpha = 0.3) +
      #geom_line(data = subset_data, aes(x = Time, y = Raw_Age), color = "cornflowerblue", size = 0.5, alpha = 0.3) +
      geom_line(data = subset_data, aes(x = Time, y = loess_Age), color = "black", size = 1, alpha = 1.5) +
      #geom_point(data = subset_data, aes(x = Time, y = loess_Age), color = "black", shape = 16, size = 1.1, alpha = 0.5) +
      geom_rect(data = segments_data,
                aes(xmin = Start, xmax = End, ymin = Segment_Mean - Total_uncertainty, ymax = Segment_Mean + Total_uncertainty), 
                fill = Final_color, alpha = 0.15) +
      geom_segment(data = segments_data, aes(x = Start, xend = End, y = Segment_Mean, yend = Segment_Mean), size = 1.1, color = Final_color) +
      ggtitle(paste("Analysis:", subset_data[1, 1])) +
      labs(x = "Time (s)", y = "Age (Ma)") +
      theme(
        panel.background = element_rect(fill = "white"),
        panel.border = element_rect(color = "black", fill = NA, size = 1),
        axis.line = element_line(color = "black"), 
        axis.ticks = element_line(color = "black", size = 0.25), 
        axis.ticks.length = unit(-0.3, "cm"),
        plot.title = element_text(size = 10),
        axis.text = element_text(size = 8),
        axis.title = element_text(size = 10)
      )
    
    # Add the generated plot to the list
    plots[[length(plots) + 1]] <- d
    # Use ggsave to save the graph as a PDF file
    ggsave(
      filename = paste0("Plot_", group_counter, "_", subset_data[1, 1], ".pdf"),
      plot = d,
      device = "pdf",
      width = 2.6 * 25.4,
      height = (36 / 21) * 25.4,
      units = "mm"  # The default unit is millimeters
    )
    
    print(paste("Group", group_counter," ;",subset_data[1,1], " ;Plot has been finished"))
    segments_data$Final_step_Numbers <- sum(!is.na(segments_data$Filter_4))
    
##################### Here, the MCMC method is omitted... ######################
    
    # Save the final dataframe
    for (i in 1:nrow(segments_data)) {
      output <- rbind(output, c(
        subset_data[1, 1], group_counter, nrow(subset_data),
        segments_data$Start[i], segments_data$End[i],
        segments_data$Time_step[i],max(segments_data$Time_step), min(segments_data$Time_step),
        segments_data$standardized_Mean[i],segments_data$Segment_Mean[i],
        segments_data$Variance[i],
        segments_data$Calibration_uncertainty[i],segments_data$Plateau_uncertainty[i],segments_data$Total_uncertainty[i],
        segments_data$Filter_1[i], segments_data$Filter_2[i],
        segments_data$Filter_3[i], segments_data$Filter_4[i],
        segments_data$Plateau_Numbers[i],segments_data$Number[i],
        segments_data$Final_step_Numbers[i], segments_data$Final_Serial_Number[i],
        segments_data$Filter_4[i],segments_data$Final_total_uncertainty[i]
      ))
    }
    group_counter <- group_counter + 1
  }
}

colnames(output) <- c("Analysis", "Group", "Points",
                      "Start", "End",
                      "Integration time","Max integration time","Min integration time",
                      "Standardized mean","Segmentation mean",
                      "Variance",
                      "Calibration uncertainty","Plateau uncertainty","Total uncertainty",
                      "Filter 1", "Filter 2",
                      "Filter 3", "Filter 4",
                      "Total integration time numbers", "Plateau serial numbers",
                      "Final integration time numbers","Final Serial Number",
                      "Final age","Final total uncertainty"
)

# Export the final data
write_xlsx(output, "Output_forward.xlsx")
